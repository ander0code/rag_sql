# RAG-SQL Configuración


# Proveedor LLM (Requerido)

# Opciones compatibles: deepseek, openai, claude, groq, gemini, ollama
LLM_PROVIDER=deepseek

# Modelo específico (opcional, usa default si no se especifica)
# LLM_MODEL=deepseek-chat


# Claves API (según proveedor seleccionado)

DEEPSEEK_API_KEY=sk-your-deepseek-key
# OPENAI_API_KEY=sk-your-openai-key
# ANTHROPIC_API_KEY=sk-ant-your-claude-key
# GROQ_API_KEY=gsk_your-groq-key
# GOOGLE_API_KEY=your-google-api-key

# Ollama (local, sin clave API)
# OLLAMA_BASE_URL=http://localhost:11434


# Base de datos (Requerido)

# Opción 1: URL completa
DATABASE_URL=postgresql://user:password@localhost:5432/database_name

# Opción 2: Parámetros individuales
# DB_TYPE=postgresql  # postgresql, mysql, sqlserver, sqlite
# DB_HOST=localhost
# DB_PORT=5432
# DB_NAME=your_database
# DB_USER=your_user
# DB_PASSWORD=your_password


# Servicios Adicionales (Opcional)

# Redis para sesiones y rate limiting
# REDIS_URL=redis://localhost:6379

# Qdrant para caché semántico
# QDRANT_URL=http://localhost:6333


# Configuración de Aplicación

DEBUG=true
SESSION_TTL=1800
MAX_HISTORY=10


# Control de Tokens (Gestión de Costos)

# MAX_TOKENS_RESPONSE=500
# MAX_TOKENS_SQL=200
# MAX_TOKENS_PER_MINUTE=100000
# AI_TEMPERATURE=0.0


# Modelos por proveedor (defaults)

# DEEPSEEK_MODEL=deepseek-chat
# OPENAI_MODEL=gpt-4o-mini
# ANTHROPIC_MODEL=claude-3-haiku-20240307
# GROQ_MODEL=llama-3.1-70b-versatile
# GOOGLE_MODEL=gemini-1.5-flash
# OLLAMA_MODEL=llama3.2
